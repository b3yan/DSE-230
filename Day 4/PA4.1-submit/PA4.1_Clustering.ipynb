{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSE 230: Programming Assignment 4.1 - K-Means Cluster Analysis\n",
    "---\n",
    "#### Tasks:\n",
    "- Work with `minute_weather.csv`\n",
    "    - Use scikit-learn to perform k-means clustering (25%)\n",
    "    - Explore parallelism with scikit-learn for k-means clustering (10%)\n",
    "    - Explore parallelism with dask for k-means clustering (65%)\n",
    "- Submission on Gradescope (2 files)\n",
    "  - Completed notebook (.ipynb) or PDF with results under **PA4.1 Notebook**\n",
    "    - Make sure that all expected outputs are present\n",
    "  - An executable script (.py) exported from this notebook under **PA4.1**\n",
    "\n",
    "#### Due date: Friday 5/28/2021 at 11:59 PM PST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Scikit-Learn (25%)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1** (5%) Load Data\n",
    "- Load the \"minute_weather.csv\" into the Pandas dataframe\n",
    "- Drop the two columns [\"rowID\", \"hpwren_timestamp\"] from the dataframe\n",
    "- Print out the column names (features) from the output of the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"minute_weather.csv\" into the Pandas dataframe\n",
    "df = pd.read_csv(\"minute_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the two columns [\"rowID\", \"hpwren_timestamp\"] from the dataframe\n",
    "df = df.drop([\"rowID\", \"hpwren_timestamp\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['air_pressure', 'air_temp', 'avg_wind_direction', 'avg_wind_speed',\n",
      "       'max_wind_direction', 'max_wind_speed', 'min_wind_direction',\n",
      "       'min_wind_speed', 'rain_accumulation', 'rain_duration',\n",
      "       'relative_humidity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Print out the column names (features) from the output of the previous step\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Drop null values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2** (5%) Data preprocessing and normalization using sklearn\n",
    "- Perform train and test split with 80% of the original dataset being the training dataset and 20% of the original dataset being the testing dataset.\n",
    "    * Pass `random_state=seed` to `train_test_split` for reproducing results\n",
    "- Print the number of samples from both train and test dataset, and the summary statistics of training dataset.\n",
    "- Perform feature normalization on both the train dataset and the test dataset using StandardScaler from sklearn library. Only **train** data should be used for scaling\n",
    "- Print out the mean and standard deviation along the feature columns of both the train and the test dataset.\n",
    "\n",
    "(your output of the mean and std should be a vector of shape (1, number of features) make sure you clearly label your results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=30\n",
    "# Perform train and test split with 80% of the original dataset being the training dataset and 20% of the original dataset being the testing dataset.\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train samples: 1269458\n",
      "Number of test samples: 317365\n",
      "\n",
      "Summary statistics of training dataset:\n",
      "        air_pressure      air_temp  avg_wind_direction  avg_wind_speed  \\\n",
      "count  1.269458e+06  1.269458e+06        1.269458e+06    1.269458e+06   \n",
      "mean   9.168290e+02  6.185852e+01        1.619974e+02    2.774637e+00   \n",
      "std    3.050942e+00  1.183310e+01        9.516754e+01    2.061157e+00   \n",
      "min    9.050000e+02  3.164000e+01        0.000000e+00    0.000000e+00   \n",
      "25%    9.148000e+02  5.270000e+01        6.200000e+01    1.300000e+00   \n",
      "50%    9.167000e+02  6.242000e+01        1.820000e+02    2.200000e+00   \n",
      "75%    9.187000e+02  7.088000e+01        2.170000e+02    3.800000e+00   \n",
      "max    9.295000e+02  9.932000e+01        3.590000e+02    3.230000e+01   \n",
      "\n",
      "       max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
      "count        1.269458e+06    1.269458e+06        1.269458e+06    1.269458e+06   \n",
      "mean         1.634496e+02    3.400203e+00        1.667738e+02    2.133283e+00   \n",
      "std          9.232584e+01    2.423860e+00        9.740912e+01    1.745411e+00   \n",
      "min          0.000000e+00    1.000000e-01        0.000000e+00    0.000000e+00   \n",
      "25%          6.800000e+01    1.600000e+00        7.700000e+01    8.000000e-01   \n",
      "50%          1.870000e+02    2.700000e+00        1.800000e+02    1.600000e+00   \n",
      "75%          2.230000e+02    4.600000e+00        2.120000e+02    3.000000e+00   \n",
      "max          3.590000e+02    3.600000e+01        3.590000e+02    3.200000e+01   \n",
      "\n",
      "       rain_accumulation  rain_duration  relative_humidity  \n",
      "count       1.269458e+06   1.269458e+06       1.269458e+06  \n",
      "mean        1.763524e-03   5.217258e-01       4.761155e+01  \n",
      "std         9.511593e-01   8.049277e+01       2.621206e+01  \n",
      "min         0.000000e+00   0.000000e+00       7.000000e-01  \n",
      "25%         0.000000e+00   0.000000e+00       2.470000e+01  \n",
      "50%         0.000000e+00   0.000000e+00       4.470000e+01  \n",
      "75%         0.000000e+00   0.000000e+00       6.810000e+01  \n",
      "max         6.550100e+02   6.330500e+04       9.300000e+01  \n"
     ]
    }
   ],
   "source": [
    "# Print the number of samples from both train and test dataset, and the summary statistics of training dataset.\n",
    "print(\"Number of train samples:\", len(train))\n",
    "print(\"Number of test samples:\", len(test))\n",
    "\n",
    "print(\"\\nSummary statistics of training dataset:\\n\", train.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature normalization on both the train dataset and the test dataset using StandardScaler from sklearn library. Only train data should be used for scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scalerModel = scaler.fit(train)\n",
    "\n",
    "train_df = scalerModel.transform(train)\n",
    "test_df = scalerModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the train dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>916.828996</td>\n",
       "      <td>61.85852</td>\n",
       "      <td>161.997358</td>\n",
       "      <td>2.774637</td>\n",
       "      <td>163.449599</td>\n",
       "      <td>3.400203</td>\n",
       "      <td>166.773837</td>\n",
       "      <td>2.133283</td>\n",
       "      <td>0.001764</td>\n",
       "      <td>0.521726</td>\n",
       "      <td>47.61155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_pressure  air_temp  avg_wind_direction  avg_wind_speed  \\\n",
       "0    916.828996  61.85852          161.997358        2.774637   \n",
       "\n",
       "   max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
       "0          163.449599        3.400203          166.773837        2.133283   \n",
       "\n",
       "   rain_accumulation  rain_duration  relative_humidity  \n",
       "0           0.001764       0.521726           47.61155  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the mean and standard deviation along the feature columns of both the train and the test dataset.\n",
    "# your output of the mean and std should be a vector of shape (1, number of features) make sure you clearly label your results\n",
    "\n",
    "train_mean = pd.DataFrame(train.mean()).transpose()\n",
    "print(\"Mean of the train dataset:\\n\")\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the test dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>916.835256</td>\n",
       "      <td>61.842257</td>\n",
       "      <td>161.83767</td>\n",
       "      <td>2.772816</td>\n",
       "      <td>163.217025</td>\n",
       "      <td>3.398263</td>\n",
       "      <td>167.036762</td>\n",
       "      <td>2.132522</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.593392</td>\n",
       "      <td>47.536897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_pressure   air_temp  avg_wind_direction  avg_wind_speed  \\\n",
       "0    916.835256  61.842257           161.83767        2.772816   \n",
       "\n",
       "   max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
       "0          163.217025        3.398263          167.036762        2.132522   \n",
       "\n",
       "   rain_accumulation  rain_duration  relative_humidity  \n",
       "0           0.002222       0.593392          47.536897  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mean = pd.DataFrame(test.mean()).transpose()\n",
    "print(\"Mean of the test dataset:\\n\")\n",
    "test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of the train dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.050942</td>\n",
       "      <td>11.833097</td>\n",
       "      <td>95.16754</td>\n",
       "      <td>2.061157</td>\n",
       "      <td>92.325835</td>\n",
       "      <td>2.42386</td>\n",
       "      <td>97.409117</td>\n",
       "      <td>1.745411</td>\n",
       "      <td>0.951159</td>\n",
       "      <td>80.49277</td>\n",
       "      <td>26.212061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_pressure   air_temp  avg_wind_direction  avg_wind_speed  \\\n",
       "0      3.050942  11.833097            95.16754        2.061157   \n",
       "\n",
       "   max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
       "0           92.325835         2.42386           97.409117        1.745411   \n",
       "\n",
       "   rain_accumulation  rain_duration  relative_humidity  \n",
       "0           0.951159       80.49277          26.212061  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_std = pd.DataFrame(train.std()).transpose()\n",
    "print(\"Standard deviation of the train dataset:\\n\")\n",
    "train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of the test dataset:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.053774</td>\n",
       "      <td>11.831213</td>\n",
       "      <td>95.370391</td>\n",
       "      <td>2.059166</td>\n",
       "      <td>92.532645</td>\n",
       "      <td>2.420399</td>\n",
       "      <td>97.676885</td>\n",
       "      <td>1.745084</td>\n",
       "      <td>0.999889</td>\n",
       "      <td>83.76942</td>\n",
       "      <td>26.193555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   air_pressure   air_temp  avg_wind_direction  avg_wind_speed  \\\n",
       "0      3.053774  11.831213           95.370391        2.059166   \n",
       "\n",
       "   max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
       "0           92.532645        2.420399           97.676885        1.745084   \n",
       "\n",
       "   rain_accumulation  rain_duration  relative_humidity  \n",
       "0           0.999889       83.76942          26.193555  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_std = pd.DataFrame(test.std()).transpose()\n",
    "print(\"Standard deviation of the test dataset:\\n\")\n",
    "test_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Clustering Model\n",
    "**1.4** (10%) KMeans Clustering model with sklearn\n",
    "- Use the normalized training dataset to fit a K-means model with 9 clusters\n",
    "    * Pass `random_state=seed` to `KMeans` for reproducing results\n",
    "- Print out the cluster centers found by the model\n",
    "- Print out the computational performance by adding \"%%time\" at the top of the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster centers:\n",
      " [[ 2.59868315e-01  1.75228455e-01 -1.13790121e+00 -4.92643104e-01\n",
      "  -1.03013843e+00 -5.17690463e-01 -1.30453954e+00 -4.33255888e-01\n",
      "  -1.79603979e-03 -4.65640190e-03 -3.20088310e-01]\n",
      " [-2.08209794e-01  5.52504796e-01  3.90729412e-01  5.42615774e-01\n",
      "   4.92516732e-01  4.81142090e-01  2.29786096e-01  5.92013801e-01\n",
      "  -1.83654932e-03 -6.09172449e-03 -1.78486455e-01]\n",
      " [ 1.24012683e+00 -2.12520363e-01 -1.15096346e+00  1.78204711e+00\n",
      "  -1.05358787e+00  1.87346820e+00 -1.30046064e+00  1.58664606e+00\n",
      "  -1.83395671e-03 -5.51395856e-03 -1.10716615e+00]\n",
      " [-2.78753032e-01 -1.02693213e+00  4.45427665e-01 -3.16633180e-01\n",
      "   6.12278062e-01 -3.01395137e-01  2.10001190e-01 -3.31822591e-01\n",
      "  -1.37065237e-03  2.77529357e-03  1.22513780e+00]\n",
      " [-1.51536685e-01 -5.76224663e-01 -3.32718879e-01  1.11201165e+00\n",
      "  -1.96221054e-01  1.10009030e+00 -5.28087370e-01  1.10769536e+00\n",
      "   6.48866201e+02  6.26290184e+02  5.88347083e-01]\n",
      " [ 2.98608026e-01  2.74314807e-01 -1.52556938e+00 -6.12719203e-01\n",
      "  -1.20436255e+00 -5.38770930e-01  1.79835155e+00 -6.63748632e-01\n",
      "  -1.83135656e-03 -5.48292590e-03 -3.55760639e-01]\n",
      " [-1.05033632e+00 -8.95957477e-01  4.26928281e-01  1.71158401e+00\n",
      "   5.16922476e-01  1.64809233e+00  2.56493393e-01  1.73392403e+00\n",
      "   3.79512399e-04  2.15989194e-02  9.74117263e-01]\n",
      " [ 8.95382148e-02  6.81535980e-01  7.12827142e-01 -6.59229047e-01\n",
      "   9.23138741e-01 -6.40688385e-01  4.46912037e-01 -6.62672088e-01\n",
      "  -1.84563402e-03 -6.23430697e-03 -5.69404064e-01]\n",
      " [ 2.36649596e-01  2.80028672e-01  1.89146265e+00 -6.49450373e-01\n",
      "  -1.54778304e+00 -5.71150454e-01  1.46577055e+00 -7.07959152e-01\n",
      "  -1.83849484e-03 -5.60747995e-03 -2.63493922e-01]]\n",
      "CPU times: user 2min 15s, sys: 1min 40s, total: 3min 56s\n",
      "Wall time: 21.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans = KMeans(n_clusters=9, random_state=seed).fit(train_df)\n",
    "print('cluster centers:\\n', kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "\n",
    "**1.5** (5%) Evaluate KMeans clustering model with sklearn\n",
    "- Print out the inertia_ variable of the model, and explain what the number means in KMeans model\n",
    "- Print out the within-cluster sum of squares (WSSE) on the train and test\n",
    "\n",
    "Check documentations on KMeans at https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inertia variable = 4200082.403069052 \n",
      "It means how far away the points within a cluster are. Lower values are better and zero is optimal.\n"
     ]
    }
   ],
   "source": [
    "print('inertia variable =', kmeans.inertia_, '\\nIt means how far away the points within a cluster are. Lower values are better and zero is optimal.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSE_train = 4200082.403069052\n",
      "WSSE_test = 1273945.1265774432\n"
     ]
    }
   ],
   "source": [
    "print('WSSE_train =', -kmeans.score(train_df))\n",
    "print('WSSE_test =', -kmeans.score(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parallelism with Scikit-Learn (10%)\n",
    "**2.1** (10%) Single machine parallelism using **all** the cores\n",
    "- Fit the model with single-machine parallelism using scikit-learn and joblib (via `n_jobs` parameter)\n",
    "    * Pass `random_state=seed` to `KMeans` for reproducing results\n",
    "- Print out the WSSE on train and test\n",
    "- Use %%time to print out the computational performance\n",
    "\n",
    "Note that your model's parameters and seed setting should remain the same from the previous questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSE_train = 4200082.403069052\n",
      "WSSE_test = 1273945.1265774432\n",
      "CPU times: user 2min 25s, sys: 1min 36s, total: 4min 2s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "kmeans_p = KMeans(n_clusters = 9, random_state = seed)\n",
    "\n",
    "with joblib.Parallel(n_jobs=-1):\n",
    "    kmeans_p.fit(train_df)\n",
    "\n",
    "print('WSSE_train =', -kmeans_p.score(train_df))\n",
    "print('WSSE_test =', -kmeans_p.score(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Parallelism with Dask (65%)\n",
    "Multi-machine parallelism using Dask's scalable k-means algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and connect to client\n",
    "**3.1** (5%) Setup the Dask distributed client\n",
    "- Create a Dask distributed client with 2 workers\n",
    "- Print out the Dask client information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask.distributed import Client\n",
    "\n",
    "# Start and connect to local client\n",
    "client = Client(n_workers=2)\n",
    "\n",
    "# client = Client(\"scheduler-address:8786\")  # connecting to remote cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:44141</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>16</li>\n",
       "  <li><b>Memory: </b>15.64 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:44141' processes=2 threads=16, memory=15.64 GiB>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data into Dask DataFrame\n",
    "\n",
    "**3.2** (5%) Load the data into Dask Dataframe\n",
    "- Load the dataset into Dask Dataframe\n",
    "- Use %%time to print out the loading efficiency of the operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 218 ms, sys: 52.7 ms, total: 271 ms\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>hpwren_timestamp</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-10 00:00:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.76</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-09-10 00:01:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>63.86</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-09-10 00:02:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.22</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-09-10 00:03:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.40</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-10 00:04:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.40</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowID     hpwren_timestamp  air_pressure  air_temp  avg_wind_direction  \\\n",
       "0      0  2011-09-10 00:00:49         912.3     64.76                97.0   \n",
       "1      1  2011-09-10 00:01:49         912.3     63.86               161.0   \n",
       "2      2  2011-09-10 00:02:49         912.3     64.22                77.0   \n",
       "3      3  2011-09-10 00:03:49         912.3     64.40                89.0   \n",
       "4      4  2011-09-10 00:04:49         912.3     64.40               185.0   \n",
       "\n",
       "   avg_wind_speed  max_wind_direction  max_wind_speed  min_wind_direction  \\\n",
       "0             1.2               106.0             1.6                85.0   \n",
       "1             0.8               215.0             1.5                43.0   \n",
       "2             0.7               143.0             1.2               324.0   \n",
       "3             1.2               112.0             1.6                12.0   \n",
       "4             0.4               260.0             1.0               100.0   \n",
       "\n",
       "   min_wind_speed  rain_accumulation  rain_duration  relative_humidity  \n",
       "0             1.0                NaN            NaN               60.5  \n",
       "1             0.2                0.0            0.0               39.9  \n",
       "2             0.3                0.0            0.0               43.0  \n",
       "3             0.7                0.0            0.0               49.5  \n",
       "4             0.1                0.0            0.0               58.8  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import dask.dataframe as dd\n",
    "df_dd = dd.read_csv('minute_weather.csv')\n",
    "df_dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data using Dask\n",
    "\n",
    "**3.3** (5%) Summary statistics\n",
    "- Print out the shape of the dataframe\n",
    "- Print the first 10 rows of the dask dataframe\n",
    "- Print the summary statistics on all the features of the dask dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe:\n",
      " ( 1587257 , 13 )\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the dataframe:\\n', '(', df_dd.shape[0].compute(), ',', len(df_dd.columns), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rowID</th>\n",
       "      <th>hpwren_timestamp</th>\n",
       "      <th>air_pressure</th>\n",
       "      <th>air_temp</th>\n",
       "      <th>avg_wind_direction</th>\n",
       "      <th>avg_wind_speed</th>\n",
       "      <th>max_wind_direction</th>\n",
       "      <th>max_wind_speed</th>\n",
       "      <th>min_wind_direction</th>\n",
       "      <th>min_wind_speed</th>\n",
       "      <th>rain_accumulation</th>\n",
       "      <th>rain_duration</th>\n",
       "      <th>relative_humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2011-09-10 00:00:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.76</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-09-10 00:01:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>63.86</td>\n",
       "      <td>161.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>215.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-09-10 00:02:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.22</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>143.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-09-10 00:03:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.40</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-09-10 00:04:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>64.40</td>\n",
       "      <td>185.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>260.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-09-10 00:05:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>63.50</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2011-09-10 00:06:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>62.78</td>\n",
       "      <td>79.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2011-09-10 00:07:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>62.42</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>75.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>2011-09-10 00:08:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>62.24</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2011-09-10 00:09:49</td>\n",
       "      <td>912.3</td>\n",
       "      <td>62.24</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rowID     hpwren_timestamp  air_pressure  air_temp  avg_wind_direction  \\\n",
       "0      0  2011-09-10 00:00:49         912.3     64.76                97.0   \n",
       "1      1  2011-09-10 00:01:49         912.3     63.86               161.0   \n",
       "2      2  2011-09-10 00:02:49         912.3     64.22                77.0   \n",
       "3      3  2011-09-10 00:03:49         912.3     64.40                89.0   \n",
       "4      4  2011-09-10 00:04:49         912.3     64.40               185.0   \n",
       "5      5  2011-09-10 00:05:49         912.3     63.50                76.0   \n",
       "6      6  2011-09-10 00:06:49         912.3     62.78                79.0   \n",
       "7      7  2011-09-10 00:07:49         912.3     62.42                86.0   \n",
       "8      8  2011-09-10 00:08:49         912.3     62.24               105.0   \n",
       "9      9  2011-09-10 00:09:49         912.3     62.24                93.0   \n",
       "\n",
       "   avg_wind_speed  max_wind_direction  max_wind_speed  min_wind_direction  \\\n",
       "0             1.2               106.0             1.6                85.0   \n",
       "1             0.8               215.0             1.5                43.0   \n",
       "2             0.7               143.0             1.2               324.0   \n",
       "3             1.2               112.0             1.6                12.0   \n",
       "4             0.4               260.0             1.0               100.0   \n",
       "5             2.5                92.0             3.0                61.0   \n",
       "6             2.4                89.0             2.7                62.0   \n",
       "7             2.0                92.0             2.4                75.0   \n",
       "8             1.4               125.0             1.9                82.0   \n",
       "9             0.4               126.0             0.7                14.0   \n",
       "\n",
       "   min_wind_speed  rain_accumulation  rain_duration  relative_humidity  \n",
       "0             1.0                NaN            NaN               60.5  \n",
       "1             0.2                0.0            0.0               39.9  \n",
       "2             0.3                0.0            0.0               43.0  \n",
       "3             0.7                0.0            0.0               49.5  \n",
       "4             0.1                0.0            0.0               58.8  \n",
       "5             2.0                0.0            0.0               62.6  \n",
       "6             2.0                0.0            0.0               65.6  \n",
       "7             1.8                0.0            0.0               65.2  \n",
       "8             1.0                0.0            0.0               65.8  \n",
       "9             0.2                0.0            0.0               58.6  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first 10 rows of the dask dataframe\n",
    "df_dd.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              rowID  air_pressure      air_temp  avg_wind_direction  \\\n",
      "count  1.587257e+06  1.587257e+06  1.587257e+06        1.586824e+06   \n",
      "mean   7.936280e+05  9.168301e+02  6.185144e+01        1.619654e+02   \n",
      "std    4.582018e+05  3.051593e+00  1.183362e+01        9.520812e+01   \n",
      "min    0.000000e+00  9.050000e+02  3.164000e+01        0.000000e+00   \n",
      "25%    3.966915e+05  9.150000e+02  5.810000e+01        9.900000e+01   \n",
      "50%    7.933840e+05  9.166000e+02  6.422000e+01        1.890000e+02   \n",
      "75%    1.185527e+06  9.185000e+02  7.988000e+01        2.170000e+02   \n",
      "max    1.587256e+06  9.295000e+02  9.950000e+01        3.590000e+02   \n",
      "\n",
      "       avg_wind_speed  max_wind_direction  max_wind_speed  min_wind_direction  \\\n",
      "count    1.586824e+06        1.586824e+06    1.586824e+06        1.586824e+06   \n",
      "mean     2.774272e+00        1.634030e+02    3.399813e+00        1.668264e+02   \n",
      "std      2.060758e+00        9.236723e+01    2.423167e+00        9.746275e+01   \n",
      "min      0.000000e+00        0.000000e+00    1.000000e-01        0.000000e+00   \n",
      "25%      1.300000e+00        9.700000e+01    1.700000e+00        1.020000e+02   \n",
      "50%      2.200000e+00        1.960000e+02    2.800000e+00        1.830000e+02   \n",
      "75%      3.900000e+00        2.260000e+02    4.700000e+00        2.120000e+02   \n",
      "max      3.230000e+01        3.590000e+02    3.600000e+01        3.590000e+02   \n",
      "\n",
      "       min_wind_speed  rain_accumulation  rain_duration  relative_humidity  \n",
      "count    1.586824e+06       1.587256e+06   1.587256e+06       1.587257e+06  \n",
      "mean     2.133130e+00       1.854836e-03   5.361460e-01       4.760837e+01  \n",
      "std      1.745345e+00       9.609716e-01   8.114766e+01       2.621454e+01  \n",
      "min      0.000000e+00       0.000000e+00   0.000000e+00       7.000000e-01  \n",
      "25%      9.000000e-01       0.000000e+00   0.000000e+00       3.000000e+01  \n",
      "50%      1.700000e+00       0.000000e+00   0.000000e+00       4.540000e+01  \n",
      "75%      3.100000e+00       0.000000e+00   0.000000e+00       7.000000e+01  \n",
      "max      3.200000e+01       6.550100e+02   6.330500e+04       9.300000e+01  \n"
     ]
    }
   ],
   "source": [
    "#Print the summary statistics on all the features of the dask dataframe\n",
    "print(df_dd.describe().compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data using Dask \n",
    "\n",
    "**3.4** (5%) Data Preparation with Dask DataFrame\n",
    "- Drop the [\"rowID\", \"hpwren_timestamp\"] two columns from the dataframe\n",
    "- Perform 80/20 train and test split with `random_state=seed` (same as the previous task but in dask)\n",
    "- Print out the number of samples in train and test dataset\n",
    "\n",
    "Note that numbers of samples are slightly difference since Dask and scikit-learn are different implementations, and also due to round-off differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dd = df_dd.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the [\"rowID\", \"hpwren_timestamp\"] two columns from the dataframe\n",
    "df_dd = df_dd.drop([\"rowID\", \"hpwren_timestamp\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 80/20 train and test split with random_state=seed (same as the previous task but in dask)\n",
    "from dask_ml.model_selection import train_test_split\n",
    "train_dd, test_dd = train_test_split(df_dd, test_size=0.2, random_state=seed, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train dataset:\n",
      " 1269940\n",
      "Number of samples in test dataset:\n",
      " 316883\n"
     ]
    }
   ],
   "source": [
    "# Print out the number of samples in train and test dataset\n",
    "print('Number of samples in train dataset:\\n', train_dd.shape[0].compute())\n",
    "print('Number of samples in test dataset:\\n', test_dd.shape[0].compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.5** (10%) Data preprocessing and normalization with Dask\n",
    "- Perform feature normalization using the Dask library. Use only the **train** data for scaling.\n",
    "- Print out the summary statistics of the transformed features in train and test dataframes\n",
    "- Comments on your observation on the summary statistics of the transformed features in train and test dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform feature normalization using the Dask library. Use only the train data for scaling.\n",
    "from dask_ml.preprocessing import StandardScaler\n",
    "scaler_1 = StandardScaler()\n",
    "scalerModel_1 = scaler_1.fit(train_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       air_pressure      air_temp  avg_wind_direction  avg_wind_speed  \\\n",
      "count  1.269940e+06  1.269940e+06        1.269940e+06    1.269940e+06   \n",
      "mean  -5.306615e-14 -9.653990e-16       -2.873638e-17    2.802021e-16   \n",
      "std    1.000000e+00  1.000000e+00        1.000000e+00    1.000000e+00   \n",
      "min   -3.877920e+00 -2.553604e+00       -1.700512e+00   -1.346138e+00   \n",
      "25%   -6.001063e-01 -3.175365e-01       -6.817017e-01   -7.151437e-01   \n",
      "50%   -7.565603e-02  1.996491e-01        2.845927e-01   -2.783013e-01   \n",
      "75%    5.471286e-01  1.507824e+00        5.786823e-01    5.468455e-01   \n",
      "max    4.152724e+00  3.165861e+00        2.070137e+00    1.433165e+01   \n",
      "\n",
      "       max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
      "count        1.269940e+06    1.269940e+06        1.269940e+06    1.269940e+06   \n",
      "mean         9.650410e-17    1.478894e-16        2.264892e-17   -1.555882e-16   \n",
      "std          1.000000e+00    1.000000e+00        1.000000e+00    1.000000e+00   \n",
      "min         -1.768636e+00   -1.361679e+00       -1.711532e+00   -1.222212e+00   \n",
      "25%         -7.318650e-01   -7.012527e-01       -6.651105e-01   -7.063686e-01   \n",
      "50%          3.536318e-01   -2.472095e-01        1.658710e-01   -2.478411e-01   \n",
      "75%          6.784687e-01    5.370470e-01        4.633830e-01    5.545820e-01   \n",
      "max          2.118579e+00    1.234217e+01        1.971461e+00    1.711889e+01   \n",
      "\n",
      "       rain_accumulation  rain_duration  relative_humidity  \n",
      "count       1.269940e+06   1.269940e+06       1.269940e+06  \n",
      "mean        7.553370e-20  -1.555435e-18       4.603192e-16  \n",
      "std         1.000000e+00   1.000000e+00       1.000000e+00  \n",
      "min        -1.643600e-03  -7.504024e-03      -1.789382e+00  \n",
      "25%        -1.643600e-03  -7.504024e-03      -6.610106e-01  \n",
      "50%        -1.643600e-03  -7.504024e-03      -8.394808e-02  \n",
      "75%        -1.643600e-03  -7.504024e-03       8.546130e-01  \n",
      "max         8.559063e+02   1.005067e+03       1.732130e+00  \n",
      "        air_pressure       air_temp  avg_wind_direction  avg_wind_speed  \\\n",
      "count  316883.000000  316883.000000       316883.000000   316883.000000   \n",
      "mean       -0.000926      -0.000944            0.003220        0.002202   \n",
      "std         1.001140       0.999764            0.999946        1.001258   \n",
      "min        -3.877920      -2.523181           -1.700512       -1.346138   \n",
      "25%        -0.600106      -0.302325           -0.576670       -0.715144   \n",
      "50%        -0.075656       0.214860            0.274090       -0.278301   \n",
      "75%         0.547129       1.538247            0.578682        0.546846   \n",
      "max         4.152724       3.181072            2.070137       14.234575   \n",
      "\n",
      "       max_wind_direction  max_wind_speed  min_wind_direction  min_wind_speed  \\\n",
      "count       316883.000000   316883.000000       316883.000000   316883.000000   \n",
      "mean             0.003384        0.001872           -0.000271        0.002063   \n",
      "std              1.000712        1.001013            0.999366        1.001805   \n",
      "min             -1.768636       -1.361679           -1.711532       -1.222212   \n",
      "25%             -0.629000       -0.701253           -0.654851       -0.706369   \n",
      "50%              0.353632       -0.247209            0.165871       -0.247841   \n",
      "75%              0.700125        0.537047            0.463383        0.554582   \n",
      "max              2.118579       13.456640            1.971461       16.889625   \n",
      "\n",
      "       rain_accumulation  rain_duration  relative_humidity  \n",
      "count      316883.000000  316883.000000      316883.000000  \n",
      "mean            0.003909       0.005042          -0.000705  \n",
      "std             1.972456       2.075231           0.999625  \n",
      "min            -0.001644      -0.007504          -1.789382  \n",
      "25%            -0.001644      -0.007504          -0.728732  \n",
      "50%            -0.001644      -0.007504          -0.083948  \n",
      "75%            -0.001644      -0.007504           0.850798  \n",
      "max           836.488625     897.899657           1.732130  \n"
     ]
    }
   ],
   "source": [
    "# Print out the summary statistics of the transformed features in train and test dataframes\n",
    "train_df_1 = scalerModel_1.transform(train_dd)\n",
    "test_df_1 = scalerModel_1.transform(test_dd)\n",
    "print(train_df_1.describe().compute())\n",
    "print(test_df_1.describe().compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By observing on the summary statistics of the transformed features in train and test dataframe, we can tell that basically both train and test dataframes have similar central tendency, dispersion and distribution.\n"
     ]
    }
   ],
   "source": [
    "# Comments on your observation on the summary statistics of the transformed features in train and test dataframes\n",
    "print('By observing on the summary statistics of the transformed features in train and test dataframe, we can tell that basically both train and test dataframes have similar central tendency, dispersion and distribution.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dask K-Means Model\n",
    "**3.6** (15%) KMeans clustering model with dask\n",
    "- Fit KMeans model with Dask cluster library with the transformed Dask dataframe, you should set cluster number `n_clusters` and `random_state` as the same number as previous task\n",
    "- Print out the computational performance using %%time\n",
    "\n",
    "Note that Dask's K-Means estimator uses kmeans|| as the default algorithm.  To compare to scikit-learn's implementation of k-means, use k-means++ instead.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: dask in /usr/local/lib/python3.8/dist-packages (2021.5.0)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.8/dist-packages (from dask) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask) (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: dask[distributed] in /usr/local/lib/python3.8/dist-packages (2021.5.0)\n",
      "Requirement already satisfied, skipping upgrade: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (1.6.0)\n",
      "Requirement already satisfied, skipping upgrade: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (0.8.7)\n",
      "Requirement already satisfied, skipping upgrade: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (0.11.1)\n",
      "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (5.4.1)\n",
      "Requirement already satisfied, skipping upgrade: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: distributed==2021.05.0; extra == \"distributed\" in /usr/local/lib/python3.8/dist-packages (from dask[distributed]) (2021.5.0)\n",
      "Requirement already satisfied, skipping upgrade: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask[distributed]) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: tornado>=6.0.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (6.1)\n",
      "Requirement already satisfied, skipping upgrade: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /usr/lib/python3/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (45.2.0)\n",
      "Requirement already satisfied, skipping upgrade: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (7.1.2)\n",
      "Requirement already satisfied, skipping upgrade: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (5.8.0)\n",
      "Requirement already satisfied, skipping upgrade: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (1.7.0)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (2.3.0)\n",
      "Requirement already satisfied, skipping upgrade: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (1.0.2)\n",
      "Requirement already satisfied, skipping upgrade: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed==2021.05.0; extra == \"distributed\"->dask[distributed]) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --upgrade dask[distributed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.93 s, sys: 9.88 s, total: 14.8 s\n",
      "Wall time: 39.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Fit KMeans model with Dask cluster library with the transformed Dask dataframe, you should set cluster number n_clusters and random_state as the same number as previous task\n",
    "from dask_ml.cluster import KMeans\n",
    "km = KMeans(n_clusters=9, random_state = seed, init = 'k-means++') \n",
    "\n",
    "with joblib.parallel_backend(\"dask\"):\n",
    "    km.fit(train_df_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Dask K-Means Model\n",
    "**3.7** (5%) Analyse hyperparameters\n",
    "- Print out the inertia_ of KMeans model\n",
    "- Print out the computational efficiency with %%time\n",
    "- Double check if the dataframes and hyperparameters are the same for both scikit-learn K-Means model and Dask K-Means model. Is the inertia_ you printed different from your answer from the previous question? Explain your observation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.8** (10%) Dask K-Means estimator does not have a score() method.  As an easy fix, we can instantiate a scikit-learn K-Means estimator with the fitted Dask model (i.e., just copy the cluster centers over) to use the scikit-learn K-Means score method.\n",
    "- Print out the cluster centers found by the Dask KMeans model\n",
    "- Instantiate a scikit-learn KMeans estimator and assign the cluster centers with the one from Dask model\n",
    "- Print out the WSSE on train and test using score method. (Note that WSSE is the within-cluster sum of **square** error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inertia= 2141245.023499641\n",
      "Yes, it is different from the previous one. This is smaller than the previous one. \n",
      "Scikit-learn uses joblib for single-machine parallelism. This lets you train most estimators using all the cores of your laptop or workstation.\n",
      "Dask registers a joblib backend. This lets you train those estimators using all the cores of your cluster , by changing one line of code.\n",
      "This is most useful for training large models on medium-sized datasets. \n",
      "CPU times: user 512 µs, sys: 0 ns, total: 512 µs\n",
      "Wall time: 721 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Print out the inertia_ of KMeans model\n",
    "print('inertia=', km.inertia_)\n",
    "print('Yes, it is different from the previous one. This is smaller than the previous one. \\nScikit-learn uses joblib for single-machine parallelism. This lets you train most estimators using all the cores of your laptop or workstation.\\nDask registers a joblib backend. This lets you train those estimators using all the cores of your cluster , by changing one line of code.\\nThis is most useful for training large models on medium-sized datasets. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster centers:\n",
      " [[ 8.67568330e-02  6.80799368e-01  7.09207336e-01 -6.56061337e-01\n",
      "   9.19466658e-01 -6.37833792e-01  4.42295818e-01 -6.59366884e-01\n",
      "  -1.63246209e-03 -7.18240568e-03 -5.69294272e-01]\n",
      " [-1.04989034e+00 -8.99434463e-01  4.27912491e-01  1.71149918e+00\n",
      "   5.18963271e-01  1.64852440e+00  2.55550337e-01  1.73344578e+00\n",
      "   1.12121305e-03  2.84005042e-02  9.77898545e-01]\n",
      " [-3.37881143e-01  1.54015100e-01  5.15663141e-01 -6.18067587e-01\n",
      "   7.32608219e-01 -6.80614334e-01  2.47943290e-01 -5.63078801e-01\n",
      "   7.94419104e+02  7.54183706e+02 -4.57951893e-02]\n",
      " [ 2.61146200e-01  1.76164500e-01 -1.13673663e+00 -4.92097495e-01\n",
      "  -1.02901165e+00 -5.17393952e-01 -1.30437347e+00 -4.32514216e-01\n",
      "  -1.58615790e-03 -5.38087901e-03 -3.18825525e-01]\n",
      " [ 2.38372321e-01  2.80952553e-01  1.89120133e+00 -6.47753138e-01\n",
      "  -1.54644191e+00 -5.69341762e-01  1.46507515e+00 -7.06269983e-01\n",
      "  -1.62819605e-03 -6.47615522e-03 -2.64449578e-01]\n",
      " [-2.79921116e-01 -1.02759405e+00  4.47569683e-01 -3.17779495e-01\n",
      "   6.14614812e-01 -3.02381947e-01  2.10131957e-01 -3.32964892e-01\n",
      "  -1.04689228e-03  4.25760841e-03  1.22609311e+00]\n",
      " [ 1.23968516e+00 -2.14826985e-01 -1.14965623e+00  1.78324294e+00\n",
      "  -1.05236090e+00  1.87473199e+00 -1.30135878e+00  1.58771183e+00\n",
      "  -1.61684579e-03 -6.25570678e-03 -1.10630441e+00]\n",
      " [-2.09938975e-01  5.49448707e-01  3.92030059e-01  5.50787547e-01\n",
      "   4.93904299e-01  4.88697286e-01  2.29561009e-01  6.00672580e-01\n",
      "  -1.62254800e-03 -7.03422406e-03 -1.74526654e-01]\n",
      " [ 2.96464307e-01  2.71964329e-01 -1.52395295e+00 -6.12085182e-01\n",
      "  -1.20317049e+00 -5.38264637e-01  1.79654726e+00 -6.63457731e-01\n",
      "  -1.61746882e-03 -6.24235367e-03 -3.55792842e-01]]\n"
     ]
    }
   ],
   "source": [
    "# Print out the cluster centers found by the Dask KMeans model\n",
    "print('Cluster centers:\\n', km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=9, random_state=30)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a scikit-learn KMeans estimator and assign the cluster centers with the one from Dask model\n",
    "from sklearn.cluster import KMeans\n",
    "km_2 = KMeans(n_clusters=9, random_state = seed)\n",
    "km_2.fit(km.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSE_train = 4242460.296426644\n",
      "WSSE_test = 1431340.0547391435\n"
     ]
    }
   ],
   "source": [
    "# Print out the WSSE on train and test using score method. (Note that WSSE is the within-cluster sum of square error)\n",
    "print('WSSE_train =', -km_2.score(train_df_1))\n",
    "print('WSSE_test =', -km_2.score(test_df_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSSE_train = 4242460.296426644\n",
      "WSSE_test = 1431340.0547391435\n"
     ]
    }
   ],
   "source": [
    "# Another way is to just assign dask_model.cluster_centers_ to sklearn_model.cluster_centers_, run sklearn_model.score on the test data to get WSSE.\n",
    "kmeans.cluster_centers_ = km.cluster_centers_\n",
    "print('WSSE_train =', -kmeans.score(train_df_1))\n",
    "print('WSSE_test =', -kmeans.score(test_df_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop the Dask Client\n",
    "\n",
    "**3.9** (5%) Stop the dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.client - ERROR - Failed to reconnect to scheduler after 10.00 seconds, closing client\n",
      "_GatheringFuture exception was never retrieved\n",
      "future: <_GatheringFuture finished exception=CancelledError()>\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    }
   ],
   "source": [
    "client.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
