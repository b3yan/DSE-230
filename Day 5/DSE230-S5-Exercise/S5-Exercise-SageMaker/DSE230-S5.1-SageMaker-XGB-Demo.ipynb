{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageMaker Classification Demo with XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sagemaker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define IAM role- this will be necessary when defining your model\n",
    "iam_role = get_execution_role()\n",
    "\n",
    "# Set SageMaker session handle\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "# Set the region of the instance \n",
    "my_region = sess.boto_session.region_name\n",
    "\n",
    "print(\"Success - the SageMaker instance is in the \" + my_region + \" region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set S3 bucket name and folder\n",
    "\n",
    "bucket = << BUCKET NAME >>\n",
    "prefix = \"data\"\n",
    "print('Using bucket ' + bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fname = \"s3://{}/{}/{}\".format(bucket, prefix ,\"train_data.csv\")\n",
    "train_df = pd.read_csv(data_fname)\n",
    "\n",
    "data_fname = \"s3://{}/{}/{}\".format(bucket, prefix, \"val_data.csv\")\n",
    "val_df   = pd.read_csv(data_fname)\n",
    "\n",
    "data_fname = \"s3://{}/{}/{}\".format(bucket, prefix, \"test_data.csv\")\n",
    "test_df  = pd.read_csv(data_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_df.shape)\n",
    "val_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where data preparation steps are performed\n",
    "# XGBoost expects labels to be in the first column\n",
    "# Normally we need to add labels as the first column in the data, like so:\n",
    "# np.insert(x, 0, y, axis=1)  # where x is (n,m), y is (n,1)\n",
    "# But the wine dataset already has labels in the first column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data on S3 for model to access\n",
    "* Note `index=False` and `header=False` arguments passed to `to_csv`\n",
    "* This format is required to train XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write prepared data to files\n",
    "\n",
    "train_df.to_csv('train_data.csv', index=False, header=False)\n",
    "val_df.to_csv('val_data.csv', index=False, header=False)\n",
    "test_df.to_csv('test_data.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload data to S3 for model to access\n",
    "\n",
    "key_prefix = prefix + \"/model_data\"\n",
    "train_path = sess.upload_data(\n",
    "    path='train_data.csv', bucket=bucket, key_prefix=key_prefix)\n",
    "print('Train data uploaded to ' + train_path)\n",
    "\n",
    "val_path = sess.upload_data(\n",
    "    path='val_data.csv', bucket=bucket, key_prefix=key_prefix)\n",
    "print('Validation data uploaded to ' + val_path)\n",
    "\n",
    "test_path = sess.upload_data(\n",
    "    path='test_data.csv', bucket=bucket, key_prefix=key_prefix)\n",
    "print('Test data uploaded to ' + test_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create channels for train and validation data to feed to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data channels\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_path, content_type='csv')\n",
    "s3_input_val = sagemaker.inputs.TrainingInput(s3_data=val_path, content_type='csv')\n",
    "s3_input_test = sagemaker.inputs.TrainingInput(s3_data=test_path, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model output location\n",
    "\n",
    "output_location = \"s3://{}/{}/model\".format(bucket,prefix)\n",
    "print('Training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import image_uris\n",
    "xgb_image = image_uris.retrieve(framework=\"xgboost\", region=my_region, version='latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = sagemaker.estimator.Estimator(xgb_image,\n",
    "                                          iam_role, \n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.xlarge',\n",
    "                                          # train_volume_size = 5,\n",
    "                                          output_path=output_location,\n",
    "                                          sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "# https://github.com/dmlc/xgboost/blob/master/doc/parameter.rst#learning-task-parameters\n",
    "\n",
    "xgb_model.set_hyperparameters(max_depth = 10,             \n",
    "                              objective = \"multi:softmax\",\n",
    "                              num_class = 3,\n",
    "                              num_round = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model using train and validation data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE:  This step may take several minutes\n",
    "\n",
    "# Fit model using  data channels\n",
    "xgb_model.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model for real-time inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# NOTE:  This step may take several minutes\n",
    "\n",
    "xgb_predictor = xgb_model.deploy(initial_instance_count=1,\n",
    "                                 serializer = sagemaker.serializers.CSVSerializer(),\n",
    "                                 instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-Time Inference\n",
    "### NOTE - This step can(and should) be done in a separate notebook/application\n",
    "* For the purpose of the exercise, we will extract the endpoint from the `xgb_predictor` variable\n",
    "* The actual endpoint will be available in SageMaker dashboard once the model is deployed\n",
    "* Initialize a new Predictor(usually done in a separete application) with the endpoint\n",
    "* Use it for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df.shape)\n",
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the label column and load data into an array\n",
    "\n",
    "test_df_array = test_df.drop(['Class'], axis=1).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `xgb_predictor` from the previous step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from model\n",
    "# Predictions are returned as byte object, so need to decode contents into string, then convert to number array\n",
    "\n",
    "# predictions = xgb_predictor.predict(data=test_df_array).decode('utf-8') \n",
    "# predictions_array = np.fromstring(predictions, sep=',')                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing new `Predictor` object with the endpoint, session, serializer and deserializer\n",
    "* Here, `xgb_predictor.endpoint_name` is used\n",
    "* In practice, endpoint is obtained, post model deployment, from SageMaker dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.Predictor(endpoint_name=xgb_predictor.endpoint_name,\n",
    "                                          sagemaker_session=sess,\n",
    "                                          serializer=sagemaker.serializers.CSVSerializer(),\n",
    "                                          deserializer=sagemaker.deserializers.BytesDeserializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(data=test_df_array).decode('utf-8') \n",
    "predictions_array = np.fromstring(predictions, sep=',')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "y_true = test_df['Class'].values\n",
    "y_pred = predictions_array.astype(int)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: There is a limit on the number of active endpoints\n",
    "\n",
    "xgb_predictor.delete_endpoint()\n",
    "# xgb_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set S3 location for model input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nolabel_df = test_df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nolabel_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_path = \"s3://{}/{}/model_data/{}\".format(bucket,prefix,\"test_batch_data.csv\")\n",
    "test_nolabel_df.to_csv(test_batch_path, index=False, header=False)\n",
    "print('Test data for batch inference uploaded to ' + test_batch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch_output = \"s3://{}/{}/batch_output\".format(bucket,prefix)\n",
    "print('test outputs will be uploaded to: {}'.format(test_batch_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start transformer job for batch inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_transformer = xgb_model.transformer(instance_count=1,\n",
    "                                        instance_type='ml.m5.large',\n",
    "                                        output_path=test_batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Note:  This step may take several minutes\n",
    "\n",
    "xgb_transformer.transform(test_batch_path, content_type=\"text/csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_batch_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get inference results from S3\n",
    "\n",
    "fname = \"{}/{}\".format(test_batch_output, \"test_batch_data.csv.out\")\n",
    "batch_df = pd.read_csv(fname, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "\n",
    "y_true = test_df['Class'].values\n",
    "y_pred = batch_df.values.astype(int)\n",
    "# y_pred = batch_df.to_numpy()\n",
    "\n",
    "print(y_pred.T)\n",
    "print(y_true)\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost-tuning.html\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter\n",
    "\n",
    "# Specify tuning job parameters\n",
    "hyperparameter_ranges = {\n",
    "    'max_depth': IntegerParameter(1, 10),\n",
    "    'min_child_weight': IntegerParameter(1,10)}\n",
    "\n",
    "# Create tuning job\n",
    "Optimizer = sagemaker.tuner.HyperparameterTuner(\n",
    "    estimator=xgb_model,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    base_tuning_job_name='XGBoost-Tuner',\n",
    "    objective_type='Minimize',\n",
    "    objective_metric_name='validation:merror',\n",
    "    max_jobs=10,\n",
    "    max_parallel_jobs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Note:  This step may take several minutes\n",
    "\n",
    "# Launch tuning job\n",
    "Optimizer.fit({'train': s3_input_train, 'validation': s3_input_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tuning results in a df\n",
    "\n",
    "tuning_results = Optimizer.analytics().dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Deploy tuned model\n",
    "\n",
    "tuned_model_predictor = Optimizer.deploy(initial_instance_count=1,\n",
    "                    instance_type='ml.m5.xlarge', serializer = sagemaker.serializers.CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hyperparameters of tuned model\n",
    "\n",
    "Optimizer.best_estimator().hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions from tuned model\n",
    "\n",
    "predictions_tuned = tuned_model_predictor.predict(data=test_df_array).decode('utf-8') # predict!\n",
    "predictions_array_tuned = np.fromstring(predictions_tuned, sep=',') # and turn the prediction into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate evaluation metrics\n",
    "\n",
    "y_true = test_df['Class'].values\n",
    "y_pred = predictions_array.astype(int)\n",
    "\n",
    "print(y_pred)\n",
    "print(y_true)\n",
    "\n",
    "print(\"Accuracy : %.3f\" % accuracy_score(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
