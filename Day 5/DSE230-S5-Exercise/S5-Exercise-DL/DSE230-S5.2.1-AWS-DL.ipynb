{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Transfer Learning on Cats-Dogs Classification\n",
    "\n",
    "### VGG16 trained on ImageNet data is used as pre-trained model from which to extract features.  Features are then saved, and passed through neural network with ReLu hidden layer to classify cats vs. dogs.\n",
    "\n",
    "#### Adapted from fchollet/classifier_from_little_data_script_2.py (https://gist.github.com/fchollet/f35fbc80e066a49d65f1688a7e99f069) and blog https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import applications\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random generator seed\n",
    "seed = 123\n",
    "\n",
    "# Set python built-in random generator\n",
    "import random                             \n",
    "random.seed(seed)\n",
    "\n",
    "# Set numpy random generator\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set tensorflow random generator\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and extract datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://dse230-exercise.s3-us-west-2.amazonaws.com/data/train.gz\n",
    "!tar -xzf train.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://dse230-exercise.s3-us-west-2.amazonaws.com/data/validation.zip\n",
    "!unzip -q validation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://dse230-exercise.s3-us-west-2.amazonaws.com/data/test.zip\n",
    "!unzip -q test.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dimensions, number, and location of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image dimensions\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# Location of images\n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'\n",
    "test_data_dir = 'test'\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)\n",
    "    \n",
    "print (input_shape)\n",
    "\n",
    "# Number of images\n",
    "nb_train_samples = 2000\n",
    "nb_validation_samples = 400\n",
    "nb_test_samples = 400\n",
    "\n",
    "# Batch size\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method to extract features from pre-trained network and save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_features():\n",
    "    \n",
    "    # Scale pixel values in image\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Load the VGG16 network's imagenet weights, not including the last fully connected layers.\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # Generator that will read pictures found in subfolders of training data directory,\n",
    "    # and indefinitely generate batches of image data (scaled)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,        # Generator will only yield batches of data, no labels\n",
    "        shuffle=False)          # Data will be presented in order, i.e., 1000 cat images, then 1000 dog images\n",
    "    \n",
    "    # The predict_generator method returns the output of the model, given input provided by a generator\n",
    "    # that yields batches of numpy data\n",
    "    features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    \n",
    "    # Save model outputs (i.e., features) from model as numpy array\n",
    "    np.save('features_train.npy', features_train) \n",
    "\n",
    "    # Generator to generator validation input for model\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    # Get model output for validation data\n",
    "    features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    \n",
    "    # Save model outputs (i.e., features) for validation data\n",
    "    np.save('features_validation.npy', features_validation) \n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        test_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    # Get model output for validation data\n",
    "    features_test = model.predict_generator(\n",
    "        generator, nb_test_samples // batch_size)\n",
    "    \n",
    "    # Save model outputs (i.e., features) for validation data\n",
    "    np.save('features_test.npy', features_test) \n",
    "    \n",
    "    \n",
    "    # Print out model architecture\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call `save_features` method to extract and save features from pre-trained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "<< YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved features using `np.load`. Print shapes of train, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved features for train data\n",
    "train_data = << YOUR CODE HERE >>\n",
    "    \n",
    "# Create labels for train data.  Images were generated in order, so creating labels is easy.\n",
    "train_labels = np.array([0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2)) \n",
    "\n",
    "# Load saved features for validation data\n",
    "validation_data =<< YOUR CODE HERE >> \n",
    "    \n",
    "# Create labels for validation data\n",
    "validation_labels = np.array([0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "# Load saved features for test data\n",
    "test_data = << YOUR CODE HERE >> \n",
    "    \n",
    "# Create labels for test data\n",
    "test_labels = np.array([0] * (nb_test_samples // 2) + [1] * (nb_test_samples // 2)) \n",
    "    \n",
    "<< YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create fully connected layer on top of model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=train_data.shape[1:]))  # Convert 3D feature maps to 1D feature vectors\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Create model\n",
    "top_model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print model [summary](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<< YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train top model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up model\n",
    "epochs = 50\n",
    "\n",
    "# Train model, keeping track of history\n",
    "from tensorflow.keras.callbacks import History\n",
    "hist = top_model.fit(train_data, train_labels,\n",
    "                 epochs=epochs,\n",
    "                 batch_size=batch_size,\n",
    "                 validation_data=(validation_data, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model & weights to HDF5 file\n",
    "top_model_file = 'features_model' \n",
    "top_model.save(top_model_file + '.h5')\n",
    "\n",
    "# Save model to JSON file & weights to HDF5 file\n",
    "top_model_json = top_model.to_json()\n",
    "with open(top_model_file + '.json','w') as json_file:\n",
    "    json_file.write(top_model_json)\n",
    "top_model.save_weights(top_model_file+'-wts.h5')\n",
    "\n",
    "print (top_model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on validation data using [`Model.evaluate`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<< YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model again and evaluate on validation data\n",
    "* This is to demonstrate saving and loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_model2 = tf.keras.models.load_model(top_model_file+'.h5')\n",
    "print (validation_labels.shape)\n",
    "\n",
    "<< YOUR CODE HERE >>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<< YOUR CODE HERE >>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
